<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Mai Le" />
    <meta name="description" content="Describe your website">
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.70.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">

      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/blog/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume.pdf/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      
      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
        <div class="blog-title">
          <h4>
          May 13, 2020
            &nbsp;&nbsp;
            
          </h4>
        </div>
        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<ul>
<li><strong>0. (5 pts)</strong> Introduce your dataset and each of your variables (or just your main variables if you have lots) in a paragraph. What are they measuring? How many observations?</li>
</ul>
<pre class="r"><code>social&lt;-read.csv(&quot;socsupport.csv&quot;)
social&lt;-social%&gt;%dplyr::select(-firstyr,-enrolment,-BDI,-emotionalsat,-X,-tangiblesat,-affectsat,-psisat,-esupport,-psupport)
head(social)</code></pre>
<pre><code>## gender age country marital livewith employment emotional
tangible affect psi
## 1 male 21-24 australia other partner employed part-time
22 17 15 12
## 2 female 21-24 australia single partner parental support
21 12 10 9
## 3 male 21-24 australia single residences employed
part-time 21 16 15 13
## 4 male 18-20 australia single parents employed part-time
19 20 11 13
## 5 female 21-24 australia single friends employed
part-time 16 11 6 11
## 6 female 21-24 australia single friends govt assistance
20 16 12 12
## supsources
## 1 13
## 2 10
## 3 14
## 4 15
## 5 9
## 6 13</code></pre>
<div id="my-dataset-focuses-on-social-and-other-kinds-of-support.-gender-is-a-binary-categorical-variable-indicating-the-biological-sex-of-the-participant-age-is-a-categorical-variable-with-5-levels-measuring-how-old-in-years-the-participant-is-employment-is-a-categorical-variable-with-5-levels-indicating-the-participants-working-status-marital-is-a-categorical-variable-with-3-levels-indicating-the-participants-marital-status-livewith-is-a-categorical-variable-with-6-levels-indicating-the-participants-living-situation.-emotional-tangible-and-affect-are-all-numeric-variables-on-the-availability-of-their-respective-kinds-of-support.-psi-is-a-numeric-variable-on-the-availability-of-positive-social-interaction-and-supsources-is-the-numeric-variable-on-the-extent-of-social-support-sources.-country-is-a-binomial-categorial-variable-stating-whether-the-participant-is-from-australia-or-another-country.-all-variable-firstyr-enrolment-emotionalsat-tangiblesat-affectsat-psisat-esupport-psupport-and-bdi-because-i-wasnt-as-interested-in-their-possible-relationship." class="section level3">
<h3>My dataset focuses on social and other kinds of support. ‘gender’ is a binary categorical variable indicating the biological sex of the participant, ‘age’ is a categorical variable with 5 levels measuring how old in years the participant is, ‘employment’ is a categorical variable with 5 levels indicating the participant’s working status, ‘marital’ is a categorical variable with 3 levels indicating the participant’s marital status, ‘livewith’ is a categorical variable with 6 levels indicating the participant’s living situation. ‘emotional’, ‘tangible’, and ‘affect’ are all numeric variables on the availability of their respective kinds of support. ‘psi’ is a numeric variable on the availability of positive social interaction and ‘supsources’ is the numeric variable on the extent of social support sources. “country” is a binomial categorial variable stating whether the participant is from Australia or another country. All variable ‘firstyr’, ‘enrolment’, ‘emotionalsat’, ‘tangiblesat’, ‘affectsat’, ‘psisat’, ‘esupport’, ‘psupport’, and ‘BDI’ because I wasn’t as interested in their possible relationship.</h3>
<ul>
<li><strong>1. (15 pts)</strong> Perform a MANOVA testing whether any of your numeric variables (or a subset of them, if including them all doesn’t make sense) show a mean difference across levels of one of your categorical variables (3). If they do, perform univariate ANOVAs to find response(s) showing a mean difference across groups (3), and perform post-hoc t tests to find which groups differ (3). Discuss the number of tests you have performed, calculate the probability of at least one type I error (if unadjusted), and adjust the significance level accordingly (bonferroni correction) before discussing significant differences (3). Briefly discuss assumptions and whether or not they are likely to have been met (2).</li>
</ul>
<pre class="r"><code>man1&lt;-manova(cbind(emotional, tangible, affect,psi,supsources)~livewith,data=social)
summary(man1) ### 1 manova</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## livewith 5 0.49207 1.8775 25 430 0.006909 **
## Residuals 86
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(man1) ### 2 anovas</code></pre>
<pre><code>## Response emotional :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## livewith 5 101.3 20.259 1.5638 0.1789
## Residuals 86 1114.2 12.956
##
## Response tangible :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## livewith 5 346.46 69.292 5.3107 0.0002669 ***
## Residuals 86 1122.09 13.048
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response affect :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## livewith 5 150.42 30.0834 3.8582 0.003345 **
## Residuals 86 670.57 7.7973
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response psi :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## livewith 5 46.17 9.2331 1.6529 0.1548
## Residuals 86 480.39 5.5859
##
## Response supsources :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## livewith 5 38.09 7.6175 1.3249 0.2613
## Residuals 86 494.47 5.7496
##
## 3 observations deleted due to missingness</code></pre>
<pre class="r"><code>pairwise.t.test(social$tangible, social$livewith, p.adj = &quot;none&quot;) ###15</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  social$tangible and social$livewith 
## 
##            alone  friends other  parents partner
## friends    0.1210 -       -      -       -      
## other      0.0110 0.1094  -      -       -      
## parents    0.0145 0.1812  0.3476 -       -      
## partner    0.0746 0.8555  0.0967 0.0824  -      
## residences 0.4652 0.1088  0.0041 1.3e-05 0.0131 
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(social$affect, social$livewith, p.adj = &quot;none&quot;) ###15</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  social$affect and social$livewith 
## 
##            alone friends other parents partner
## friends    0.307 -       -     -       -      
## other      0.191 0.585   -     -       -      
## parents    0.097 0.343   0.984 -       -      
## partner    0.027 0.057   0.455 0.096   -      
## residences 0.595 0.328   0.194 0.003   8.5e-05
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>0.05/(1+2+15+15)</code></pre>
<pre><code>## [1] 0.001515152</code></pre>
</div>
<div id="a-one-qay-manova-was-conducted-to-detemine-the-effect-of-participants-living-situation-alone-friends-other-parents-partner-residences-on-five-dependent-variables-tangible-affect-emotional-psi-supsources.-significant-differences-were-found-among-the-living-situations-with-at-least-one-of-the-dependent-variables-pillai-trace-0.49207-pseudo-f25-430-1.8775-p-0.05.-univariate-anovas-for-each-dependent-variable-were-conducted-as-follow-up-tests-to-the-manova-using-the-bonferroni-method-for-controlling-type-i-error-rates-for-multiple-comparisons.-the-univariate-anovas-for-affect-and-tangible-were-also-significant-f586-3.8582-p-.05-f5-86-5.3107-p-.05-respectively.-post-hoc-analysis-was-performed-conducting-pairwise-comparisons-to-determine-which-living-situation-differed-in-affect-and-tangible.-partner-and-alone-parents-and-residences-partner-and-residences-each-pair-was-found-to-differ-significantly-from-each-other-in-terms-of-affect-and-tangible-after-adjusting-for-multiple-comparitsons-0.05121515-0.001515152.-the-first-assumption-of-random-smaples-with-independent-observations-was-most-likely-met-since-this-data-was-distributed-via-survey.-however-theres-a-possibility-of-bias-in-the-data-since-this-dataset-was-obtained-mostly-in-australia-so-its-not-as-represented-as-we-would-have-liked.-no-way-for-us-to-know-just-by-looking-at-the-dataset-that-the-second-and-third-assumption-of-linear-relationships-among-dependent-variables-and-dependent-variables-shouldnt-be-too-correlated-are-met-unless-we-do-further-testing.-for-the-last-3-assumptions-we-assume-theyve-been-met-in-order-to-perform-manova.-they-are-multivariate-normality-of-dependent-homogeneity-of-within-group-covariance-matrices-and-no-extreme-univariate-or-multivariate-outliers." class="section level3">
<h3>A one-qay MANOVA was conducted to detemine the effect of participant’s living situation (alone, friends, other, parents, partner, residences) on five dependent variables (tangible, affect, emotional, psi, supsources). Significant differences were found among the living situations with at least one of the dependent variables, Pillai trace = 0.49207 pseudo F(25, 430) = 1.8775 p &lt; 0.05. Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for affect and tangible were also significant F(5,86) = 3.8582, p &lt; .05 F(5, 86) = 5.3107 p =&lt; .05, respectively. Post hoc analysis was performed conducting pairwise comparisons to determine which living situation differed in affect and tangible. Partner and alone, parents and residences, partner and residences, each pair was found to differ significantly from each other in terms of affect and tangible after adjusting for multiple comparitsons (0.05/(1+2+15+15)) = 0.001515152. The first assumption of random smaples with independent observations was most likely met since this data was distributed via survey. However, there’s a possibility of bias in the data since this dataset was obtained mostly in Australia, so it’s not as represented as we would have liked. No way for us to know just by looking at the dataset that the second and third assumption of linear relationships among dependent variables and dependent variables shouldn’t be too correlated are met unless we do further testing. For the last 3 assumptions we assume they’ve been met in order to perform MANOVA. They are multivariate normality of dependent, homogeneity of within group covariance matrices, and no extreme univariate or multivariate outliers.</h3>
<ul>
<li><strong>2. (10 pts)</strong> Perform some kind of randomization test on your data (that makes sense). This can be anything you want! State null and alternative hypotheses, perform the test, and interpret the results (7). Create a plot visualizing the null distribution and the test statistic (3).</li>
</ul>
<pre class="r"><code>obs_F&lt;-5.3107
Fs&lt;-replicate(5000,{
  new&lt;-social%&gt;%mutate(affect=sample(affect)) 
  SSW&lt;- new%&gt;%group_by(livewith)%&gt;%summarize(SSW=sum((affect-mean(affect))^2))%&gt;% summarize(sum(SSW))%&gt;%pull
  SSB&lt;- new%&gt;%mutate(mean=mean(affect))%&gt;%group_by(livewith)%&gt;%mutate(groupmean=mean(affect))%&gt;%summarize(SSB=sum((mean-groupmean)^2))%&gt;%summarize(sum(SSB))%&gt;%pull
  (SSB/5)/(SSW/86) 
})
hist(Fs, prob=T); abline(v = obs_F, col=&quot;red&quot;,add=T)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(Fs&gt;obs_F)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
<div id="the-null-hypothesis-is-the-true-mean-of-the-response-variable-affect-is-the-same-for-all-6-groups-of-living-siatuations-livewith.-the-alternative-hypothesis-is-that-at-least-one-of-these-means-differs-from-the-others.-the-p-value-is-smaller-than-0.05-and-none-of-our-5000-f-statistics-generated-under-the-null-hypothesis-were-bigger-than-our-actial-f-statistic-of-5.3107.-this-means-we-can-reject-the-null-hypothesis-and-conclude-that-the-groups-differ." class="section level3">
<h3>The null hypothesis is the true mean of the response variable, affect, is the same for all 6 groups of living siatuations (livewith). The alternative hypothesis is that at least one of these means differs from the others. The p value is smaller than 0.05 and none of our 5000 F statistics generated under the null hypothesis were bigger than our actial F statistic of 5.3107. This means we can reject the null hypothesis and conclude that the groups differ.</h3>
<ul>
<li><p><strong>3. (35 pts)</strong> Build a linear regression model predicting one of your response variables from at least 2 other variables, including their interaction. Mean-center any numeric variables involved in the interaction.</p>
<ul>
<li>Interpret the coefficient estimates (do not discuss significance) (10)</li>
<li>Plot the regression using <code>ggplot()</code>. If your interaction is numeric by numeric, refer to code near the end of WS15 to make the plot. (8)</li>
<li>Check assumptions of linearity, normality, and homoskedasticity either graphically or using a hypothesis test (4)</li>
<li>Regardless, recompute regression results with robust standard errors via <code>coeftest(..., vcov=vcovHC(...))</code>. Discuss significance of results, including any changes from before/after robust SEs if applicable. (8)</li>
<li>What proportion of the variation in the outcome does your model explain? (4)</li>
</ul></li>
</ul>
<pre class="r"><code>library(sandwich)
library(lmtest)
fit3&lt;-lm(emotional ~ affect * psi, data=social)
summary(fit3)</code></pre>
<pre><code>##
## Call:
## lm(formula = emotional ~ affect * psi, data = social)
##
## Residuals:
## Min 1Q Median 3Q Max
## -8.0140 -1.4715 -0.1233 1.5599 6.3474
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -2.26976 3.78281 -0.600 0.549984
## affect 1.31629 0.36487 3.608 0.000505 ***
## psi 1.38362 0.36113 3.831 0.000234 ***
## affect:psi -0.07258 0.03135 -2.315 0.022874 *
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 2.533 on 91 degrees of freedom
## Multiple R-squared: 0.5512, Adjusted R-squared: 0.5364
## F-statistic: 37.25 on 3 and 91 DF, p-value: 8.466e-16</code></pre>
<pre class="r"><code>#mean center numeric variable
social$psi_c &lt;- social$psi - mean(social$psi)
social$affect_c&lt;- social$affect - mean(social$affect)
fitcenter&lt;-lm(emotional ~ affect_c*psi_c, data=social)
summary(fitcenter)</code></pre>
<pre><code>##
## Call:
## lm(formula = emotional ~ affect_c * psi_c, data =
social)
##
## Residuals:
## Min 1Q Median 3Q Max
## -8.0140 -1.4715 -0.1233 1.5599 6.3474
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 19.55975 0.29393 66.546 &lt; 2e-16 ***
## affect_c 0.46140 0.11274 4.092 9.22e-05 ***
## psi_c 0.51345 0.14425 3.559 0.000593 ***
## affect_c:psi_c -0.07258 0.03135 -2.315 0.022874 *
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 2.533 on 91 degrees of freedom
## Multiple R-squared: 0.5512, Adjusted R-squared: 0.5364
## F-statistic: 37.25 on 3 and 91 DF, p-value: 8.466e-16</code></pre>
<pre class="r"><code>#plot
new1&lt;-social
new1$affect_c&lt;-mean(social$affect_c)
new1$mean&lt;-predict(fitcenter,new1)
new1$affect_c&lt;-mean(social$affect_c)+sd(social$affect_c)
new1$plus.sd&lt;-predict(fitcenter,new1)
new1$affect_c&lt;-mean(social$affect_c)-sd(social$affect_c)
new1$minus.sd&lt;-predict(fitcenter,new1)
newint&lt;-new1%&gt;%select(emotional,psi_c,mean,plus.sd,minus.sd)%&gt;%gather(affect,value,-emotional,-psi_c)

mycols&lt;-c(&quot;#619CFF&quot;,&quot;#F8766D&quot;,&quot;#00BA38&quot;)
names(mycols)&lt;-c(&quot;-1 sd&quot;,&quot;mean&quot;,&quot;+1 sd&quot;)
mycols=as.factor(mycols)

ggplot(social,aes(psi_c,emotional),group=mycols)+geom_point()+geom_line(data=new1,aes(y=mean,color=&quot;mean&quot;))+geom_line(data=new1,aes(y=plus.sd,color=&quot;+1 sd&quot;))+geom_line(data=new1,aes(y=minus.sd,color=&quot;-1 sd&quot;))+scale_color_manual(values=mycols)+labs(color=&quot;affect (cont)&quot;)+theme(legend.position=c(.9,.2))</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#assumptions
resids&lt;-fit3$residuals
fitvals&lt;-fit3$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, col=&quot;red&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(resids),bins=20)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids), color=&#39;red&#39;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-4.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#robust SE
coeftest(fitcenter, vcov = vcovHC(fitcenter))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 19.559750 0.342321 57.1387 &lt; 2.2e-16 ***
## affect_c 0.461402 0.174530 2.6437 0.009657 **
## psi_c 0.513450 0.175198 2.9307 0.004276 **
## affect_c:psi_c -0.072578 0.038549 -1.8827 0.062932 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
</div>
<div id="as-seen-with-all-three-p-values-interaction-is-significant-after-mean-centering-all-numeric-variables.-the-coefficient-psi_c-shows-that-for-every-one-unit-increase-in-the-centered-availability-of-positive-social-interaction-the-availability-of-emotional-support-is-expected-to-increase-by-0.51345.-the-coefficient-of-affect_c-shows-that-for-every-one-unit-increase-in-the-centered-availability-affectionate-support-sources-the-avaliability-of-emotional-support-is-expected-to-increase-by-0.46140.-for-those-with-average-centered-availability-of-positive-social-interaction-the-centered-availability-of-affectionate-support-sources-has-a-predicted-availability-of-emotional-support-of-0.07258-less-than-the-nonaverage.-after-recomputing-regression-results-with-robust-standard-errors-the-results-continue-to-stay-significiant.-all-the-stadard-errors-increased-from-before-robust-ses.-also-all-t-values-decreased-except-that-of-affect_cpsi_c.-the-proportion-of-variation-in-the-response-variable-explained-by-the-overall-model-is-0.5512." class="section level3">
<h3>As seen with all three p values, interaction is significant after mean centering all numeric variables. The coefficient psi_c shows that for every one unit increase in the centered availability of positive social interaction, the availability of emotional support is expected to increase by 0.51345. The coefficient of affect_c shows that for every one unit increase in the centered availability affectionate support sources, the avaliability of emotional support is expected to increase by 0.46140. For those with average centered availability of positive social interaction, the centered availability of affectionate support sources has a predicted availability of emotional support of 0.07258 less than the nonaverage. After recomputing regression results with robust standard errors, the results continue to stay significiant. All the stadard errors increased from before robust SEs. Also all t values decreased except that of affect_c:psi_c. The proportion of variation in the response variable explained by the overall model is 0.5512.</h3>
<ul>
<li><strong>4. (5 pts)</strong> Rerun same regression model (with interaction), but this time compute bootstrapped standard errors. Discuss any changes you observe in SEs and p-values using these SEs compared to the original SEs and the robust SEs)</li>
</ul>
<pre class="r"><code>boot_social&lt;- sample_frac(social, replace=T)

samp_distn&lt;-replicate(5000, {
  boot_social &lt;- sample_frac(social, replace=T) 
  fitcenter&lt;-lm(emotional ~ affect_c * psi_c, data=boot_social)
  coef(fitcenter) 
})
samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)  affect_c     psi_c affect_c:psi_c
## 1    0.316944 0.1496961 0.1623568     0.03640356</code></pre>
<pre class="r"><code>samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% gather %&gt;% group_by(key) %&gt;%summarize(lower=quantile(value,.025), upper=quantile(value,.975))</code></pre>
<pre><code>## # A tibble: 4 x 3
##   key             lower   upper
##   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)    18.9   20.1   
## 2 affect_c        0.223  0.802 
## 3 affect_c:psi_c -0.129  0.0166
## 4 psi_c           0.188  0.821</code></pre>
</div>
<div id="the-bootstrapped-ses-are-all-higher-than-those-of-the-original-but-lower-than-those-of-the-robust-ses." class="section level3">
<h3>The bootstrapped SEs are all higher than those of the original but lower than those of the robust SEs.</h3>
<ul>
<li><p><strong>5. (40 pts)</strong> Perform a logistic regression predicting a binary categorical variable (if you don’t have one, make/get one) from at least two explanatory variables (interaction not necessary).</p>
<ul>
<li>Interpret coefficient estimates in context (10)</li>
<li>Report a confusion matrix for your logistic regression (2)</li>
<li>Compute and discuss the Accuracy, Sensitivity (TPR), Specificity (TNR), and Recall (PPV) of your model (5)</li>
<li>Using ggplot, plot density of log-odds (logit) by your binary outcome variable (3)</li>
<li>Generate an ROC curve (plot) and calculate AUC (either manually or with a package); interpret (10)</li>
<li>Perform 10-fold (or repeated random sub-sampling) CV and report average out-of-sample Accuracy, Sensitivity, and Recall (10)</li>
</ul></li>
</ul>
<pre class="r"><code>library(plotROC)
library(glmnet)
social&lt;-social%&gt;%dplyr::select(-psi_c,-affect_c)
social5 &lt;- social %&gt;% mutate(y = ifelse(gender == &quot;female&quot;, 1, 0))
fit5&lt;-glm(y~age + psi, family=&quot;binomial&quot;, data=social5)
coeftest(fit5)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 0.595749 1.213060 0.4911 0.62335
## age21-24 0.256087 0.553074 0.4630 0.64335
## age25-30 0.467230 1.154648 0.4047 0.68573
## age31-40 -1.766909 0.935896 -1.8879 0.05904 .
## age40+ 0.024245 1.209515 0.0200 0.98401
## psi 0.043900 0.102036 0.4302 0.66702
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(0.256087)</code></pre>
<pre><code>## [1] 1.291865</code></pre>
<pre class="r"><code>exp(0.467230)</code></pre>
<pre><code>## [1] 1.595568</code></pre>
<pre class="r"><code>exp(-1.766909)</code></pre>
<pre><code>## [1] 0.1708603</code></pre>
<pre class="r"><code>exp( 0.024245)</code></pre>
<pre><code>## [1] 1.024541</code></pre>
<pre class="r"><code>exp(0.043900)</code></pre>
<pre><code>## [1] 1.044878</code></pre>
<pre class="r"><code>#confusion matrix
prob&lt;-predict(fit5,type=&quot;response&quot;) 
table(predict=as.numeric(prob&gt;.5),truth=social5$y)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0    4  2   6
##     1   20 69  89
##     Sum 24 71  95</code></pre>
<pre class="r"><code>69/71 #tpr</code></pre>
<pre><code>## [1] 0.971831</code></pre>
<pre class="r"><code>4/24 #tnr</code></pre>
<pre><code>## [1] 0.1666667</code></pre>
<pre class="r"><code>69/89 #ppv</code></pre>
<pre><code>## [1] 0.7752809</code></pre>
<pre class="r"><code>#plot
social5$logit&lt;-predict(fit5,type=&quot;link&quot;) 
social5%&gt;%ggplot()+geom_density(aes(logit,color=gender,fill=gender), alpha=.4)+
  theme(legend.position=c(.85,.85))+
  geom_vline(xintercept=0)+xlab(&quot;logit(log-odds)&quot;)+
  geom_rug(aes(logit,color=gender))+
  geom_text(x=-5,y=.07,label=&quot;TN = 4&quot;)+
  geom_text(x=-1.75,y=.008,label=&quot;FN = 2&quot;)+
  geom_text(x=1,y=.006,label=&quot;FP = 20&quot;)+
  geom_text(x=5,y=.04,label=&quot;TP = 69&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#roc curve and auc
pred &lt;- ifelse(prob &gt; 0.5, 1, 0)
ROCplot &lt;- ggplot(social5) + geom_roc(aes(d = y, m = prob), n.cuts = 0) +geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), lty = 2)
ROCplot</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-6-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.6012324</code></pre>
<pre class="r"><code>#10 fold
class_diag&lt;-function(probs,truth){
  
  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  prediction&lt;-ifelse(probs&gt;.5,1,0)
  acc=mean(truth==prediction)
  sens=mean(prediction[truth==1]==1)
  spec=mean(prediction[truth==0]==0)
  ppv=mean(truth[prediction==1]==1)
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

set.seed(1234)
k=10
data&lt;-social5[sample(nrow(social5)),]
folds&lt;-cut(seq(1:nrow(social5)),breaks=k,labels=F)
diags&lt;-NULL
for(i in 1:k){
  train&lt;-data[folds!=i,]
  test&lt;-data[folds==i,]
  truth&lt;-test$y
  fit5&lt;-glm(y~age + psi, data=train, family=&quot;binomial&quot;)
  probs&lt;-predict(fit5,newdata = test,type=&quot;response&quot;)
  diags&lt;-rbind(diags,class_diag(probs,truth))}

summarize_all(diags,mean) </code></pre>
<pre><code>##         acc      sens spec       ppv       auc
## 1 0.7577778 0.9746032  NaN 0.7679365 0.5315675</code></pre>
</div>
<div id="while-controlling-for-psi-no-age-group-is-signficantly-different-when-comparing-to-reference-age-group-of-18-20.-odds-of-female-for-age-group-21-24-is-1.291865-times-odds-for-18-20.-odds-of-female-for-age-group-25-30-is-1.595568-times-odds-for-18-20.-odds-of-female-for-age-group-31-40-is-0.1708603-times-odss-for-18-20.-odds-of-female-for-age-group-40-is-1.024541-times-odds-for-18-20.-controlling-for-age-for-every-one-unit-increase-in-psi-the-availability-of-positive-social-interaction-odds-of-being-a-female-change-by-a-factor-of-1.044878.-the-sensitivity-or-true-positive-rate-is-0.971831-the-specificity-or-true-negative-rate-is-0.1666667-and-the-precision-or-the-proportion-classifed-female-who-actually-are-is-0.7752809.-as-seen-on-density-plot-we-have-very-high-density-of-false-positive-where-we-predicted-female-but-theyre-actually-male-as-seen-with-the-red-region-when-logit0.-in-addition-we-have-much-lower-density-of-predicting-male-correctly-as-evident-with-the-blue-region-when-logit0.-auc-is-calculated-to-be-0.6012324-thus-the-probability-that-a-randomly-selected-person-is-a-female-has-a-higher-predicted-probability-than-a-randomly-selected-person-who-isnt-a-female.-after-performing-a-10-fold-cv-the-auc-is-now-0.4518849-sens-is-0.9690476-acc-is-0.7588889-ppv-is-0.7636111-and-spec-is-0.1.-since-the-auc-decreases-from-0.6012324-to-0.4518849-we-can-conclude-that-the-model-did-overfit-a-bit." class="section level3">
<h3>While controlling for psi, no age group is signficantly different when comparing to reference age group of 18-20. Odds of female for age group 21-24 is 1.291865 times odds for 18-20. Odds of female for age group 25-30 is 1.595568 times odds for 18-20. Odds of female for age group 31-40 is 0.1708603 times odss for 18-20. Odds of female for age group 40+ is 1.024541 times odds for 18-20. Controlling for age, for every one unit increase in psi, the availability of positive social interaction, odds of being a female change by a factor of 1.044878. The sensitivity or true positive rate is 0.971831, the specificity or true negative rate is 0.1666667, and the precision or the proportion classifed female who actually are is 0.7752809. As seen on density plot, we have very high density of false positive, where we predicted female but they’re actually male, as seen with the red region when logit&gt;0. In addition, we have much lower density of predicting male correctly, as evident with the blue region when logit&lt;0. AUC is calculated to be 0.6012324 thus the probability that a randomly selected person is a female has a higher predicted probability than a randomly selected person who isn’t a female. After performing a 10 fold CV, the auc is now 0.4518849, sens is 0.9690476, acc is 0.7588889, ppv is 0.7636111, and spec is 0.1. Since the auc decreases from 0.6012324 to 0.4518849, we can conclude that the model did overfit a bit.</h3>
<ul>
<li><strong>6. (10 pts)</strong> Choose one variable you want to predict (can be one you used from before; either binary or continuous) and run a LASSO regression inputting all the rest of your variables as predictors. Choose lambda to give the simplest model whose accuracy is near that of the best (i.e., <code>lambda.1se</code>). Discuss which variables are retained. Perform 10-fold CV using this model: if response in binary, compare model’s out-of-sample accuracy to that of your logistic regression in part 5; if response is numeric, compare the residual standard error (at the bottom of the summary output, aka RMSE): lower is better fit!</li>
</ul>
<pre class="r"><code>social2&lt;-na.omit(social)
y&lt;-as.matrix(social2$country)
x&lt;-model.matrix(country~.,data=social2)[,-1] 
x&lt;-scale(x) 
cv &lt;- cv.glmnet(x,y, family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 22 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                         s0
## (Intercept)                  -2.104134e+00
## gendermale                    .           
## age21-24                      .           
## age25-30                      .           
## age31-40                      .           
## age40+                        .           
## maritalother                  .           
## maritalsingle                 .           
## livewithfriends               .           
## livewithother                 .           
## livewithparents               .           
## livewithpartner               .           
## livewithresidences            .           
## employmentemployed part-time  .           
## employmentgovt assistance     .           
## employmentother               .           
## employmentparental support    .           
## emotional                     .           
## tangible                      .           
## affect                        .           
## psi                           4.320923e-16
## supsources                    .</code></pre>
<pre class="r"><code>#10 fold
set.seed(1234)
k=10
data &lt;- social2 %&gt;% sample_frac 
folds &lt;- ntile(1:nrow(data),n=10) 
diags&lt;-NULL
for(i in 1:k){
  train &lt;- data[folds!=i,] 
  test &lt;- data[folds==i,] 
  truth &lt;- test$country 
  fit &lt;- glm(country~psi,data=train, family=&quot;binomial&quot;)
  probs &lt;- predict(fit, newdata=test, type=&quot;response&quot;)
  diags&lt;-rbind(diags,class_diag(probs,truth))}
diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>##    acc sens spec ppv       auc
## 1 0.89  NaN    1 NaN 0.4549603</code></pre>
</div>
<div id="variable-psi-the-availability-of-positive-social-interaction-is-the-only-one-retained.-looks-like-its-the-most-predictive-variable.-auc-comes-out-to-be-0.3705357-which-decreased-more-from-that-of-the-10-fold-cv-that-was-done-in-part-5.-this-means-that-model-overfitted.-acc-comes-out-to-be-0.8933333-while-sens-and-ppv-did-not-have-a-value-and-spec-comes-out-at-1." class="section level3">
<h3>Variable psi, the availability of positive social interaction, is the only one retained. Looks like it’s the most predictive variable. AUC comes out to be 0.3705357, which decreased more from that of the 10 fold CV that was done in part 5. This means that model overfitted. ACC comes out to be 0.8933333, while sens and ppv did not have a value, and spec comes out at 1.</h3>
<pre><code>## R version 3.6.2 (2019-12-12)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
##
## Matrix products: default
##
## locale:
## [1] LC_COLLATE=English_United States.1252
LC_CTYPE=English_United States.1252
## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
## [5] LC_TIME=English_United States.1252
##
## attached base packages:
## [1] stats graphics grDevices utils datasets methods base
##
## other attached packages:
## [1] glmnet_3.0-2 Matrix_1.2-18 plotROC_2.2.1
lmtest_0.9-37 zoo_1.8-8 sandwich_2.5-1
## [7] forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 purrr_0.3.3
readr_1.3.1 tidyr_1.0.2
## [13] tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.3.0
knitr_1.27
##
## loaded via a namespace (and not attached):
## [1] Rcpp_1.0.3 lubridate_1.7.4 lattice_0.20-38
assertthat_0.2.1 digest_0.6.23
## [6] foreach_1.5.0 utf8_1.1.4 plyr_1.8.5 R6_2.4.1
cellranger_1.1.0
## [11] backports_1.1.5 reprex_0.3.0 evaluate_0.14
httr_1.4.1 blogdown_0.18
## [16] pillar_1.4.3 rlang_0.4.2 lazyeval_0.2.2
readxl_1.3.1 rstudioapi_0.10
## [21] rmarkdown_2.1 labeling_0.3 munsell_0.5.0
broom_0.5.4 compiler_3.6.2
## [26] modelr_0.1.5 xfun_0.12 pkgconfig_2.0.3 shape_1.4.4
htmltools_0.4.0
## [31] tidyselect_0.2.5 bookdown_0.18 codetools_0.2-16
fansi_0.4.1 crayon_1.3.4
## [36] dbplyr_1.4.2 withr_2.1.2 grid_3.6.2 nlme_3.1-142
jsonlite_1.6
## [41] gtable_0.3.0 lifecycle_0.1.0 DBI_1.1.0 magrittr_1.5
scales_1.1.0
## [46] cli_2.0.1 stringi_1.4.4 farver_2.0.3 fs_1.3.1
xml2_1.2.2
## [51] ellipsis_0.3.0 generics_0.0.2 vctrs_0.2.2
iterators_1.0.12 tools_3.6.2
## [56] glue_1.3.1 hms_0.5.3 yaml_2.2.0 colorspace_1.4-1
rvest_0.3.5
## [61] haven_2.2.0</code></pre>
<pre><code>## [1] &quot;2020-05-13 00:26:53 CDT&quot;</code></pre>
<pre><code>## sysname release version nodename machine
## &quot;Windows&quot; &quot;10 x64&quot; &quot;build 18362&quot; &quot;DESKTOP-793DARR&quot;
&quot;x86-64&quot;
## login user effective_user
## &quot;Mai Le&quot; &quot;Mai Le&quot; &quot;Mai Le&quot;</code></pre>
</div>

              <hr>
              <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div>
            </div>
          </div>
          <hr>
        <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
        </div>
      </div>
      
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
